{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPU9KY5bdGw3+1Vl5p0DR6E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/ML2/blob/main/Homework_4_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homework 4: Transfer Learning\n",
        "Below you see a tutorial from Keras on using transfer learning. They train their models on half  the MNIST dataset digits (i.e. digits 0-4) and “transfer” the model to the second half (i.e, digits 5-9).\n",
        "\n"
      ],
      "metadata": {
        "id": "KoIksUP1Hrrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your homework is to train on all digits and make your own handwritten data set of the 5 characters {A, B, C, D, E}  and “transfer” your MNIST trained model over to the dataset you created. In other words, train on the full MNIST datasets (i.e. digits 0-9) and transfer on the {A, B, C, D, E} image dataset.\n"
      ],
      "metadata": {
        "id": "nQC13SXQHu63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 examples of each character"
      ],
      "metadata": {
        "id": "syWMAycTNhW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please do not use any other data resources from the web such as the emnist dataset. Figuring out the challenges of making your own handwritten character dataset is part of the exercise for this homework!   \n",
        "\n"
      ],
      "metadata": {
        "id": "6RTUAjVYJU3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission instructions: Include the images you generated as part of your submission. Include any code used for the character image preprocessing. In a README file include details on your data generation process.\n"
      ],
      "metadata": {
        "id": "sjweeNk-JYul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Submit only .py/.ipynb and README files.\n",
        "\n",
        "Code source: https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/mnist_transfer_cnn.py"
      ],
      "metadata": {
        "id": "nVs-bBoZJalq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H2u08AKdHpso"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,  Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "now = datetime.datetime.now\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "img_rows, img_cols = 28, 28\n",
        "filters = 32\n",
        "pool_size = 2\n",
        "kernel_size = 3\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train, test, num_classes):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "    t = now()\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "ha2657boIIlZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6137PlepImYT",
        "outputId": "7c771a1a-6639-4669-f0de-5d9638d63aab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]\n",
        "\n",
        "# create complete model\n",
        "model = Sequential(feature_layers + classification_layers)\n",
        "\n",
        "# train model for 5-digit classification [0..4]\n",
        "train_model(model,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)\n",
        "\n",
        "# freeze feature layers and rebuild model\n",
        "for l in feature_layers:\n",
        "    l.trainable = False\n",
        "\n",
        "# transfer step: train dense layers for new classification task [5..9]\n",
        "train_model(model,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w3l1Z22IEQ1",
        "outputId": "9f2b8cf1-446e-4eee-c4d1-351c9363a7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 54s 219ms/step - loss: 1.5956 - accuracy: 0.2487 - val_loss: 1.5649 - val_accuracy: 0.4104\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 53s 220ms/step - loss: 1.5505 - accuracy: 0.3483 - val_loss: 1.5147 - val_accuracy: 0.6291\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 55s 227ms/step - loss: 1.5032 - accuracy: 0.4438 - val_loss: 1.4601 - val_accuracy: 0.7525\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 54s 224ms/step - loss: 1.4496 - accuracy: 0.5329 - val_loss: 1.3975 - val_accuracy: 0.8249\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 52s 218ms/step - loss: 1.3888 - accuracy: 0.6137 - val_loss: 1.3241 - val_accuracy: 0.8772\n",
            "Training time: 0:05:23.271962\n",
            "Test score: 1.3240958452224731\n",
            "Test accuracy: 0.8772134780883789\n",
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 20s 83ms/step - loss: 1.5824 - accuracy: 0.2801 - val_loss: 1.5458 - val_accuracy: 0.3833\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 18s 79ms/step - loss: 1.5422 - accuracy: 0.3304 - val_loss: 1.5028 - val_accuracy: 0.4458\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 18s 79ms/step - loss: 1.5039 - accuracy: 0.3903 - val_loss: 1.4601 - val_accuracy: 0.5361\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 18s 80ms/step - loss: 1.4652 - accuracy: 0.4464 - val_loss: 1.4177 - val_accuracy: 0.6036\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 18s 79ms/step - loss: 1.4252 - accuracy: 0.5065 - val_loss: 1.3752 - val_accuracy: 0.6523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DE2Zn7L9MAha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNy39y7Oo77NvqwRf/5HpCz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/ML2/blob/main/Homework_4_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homework 4: Transfer Learning\n",
        "Below you see a tutorial from Keras on using transfer learning. They train their models on half  the MNIST dataset digits (i.e. digits 0-4) and “transfer” the model to the second half (i.e, digits 5-9).\n",
        "\n"
      ],
      "metadata": {
        "id": "KoIksUP1Hrrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your homework is to train on all digits and make your own handwritten data set of the 5 characters {A, B, C, D, E}  and “transfer” your MNIST trained model over to the dataset you created. In other words, train on the full MNIST datasets (i.e. digits 0-9) and transfer on the {A, B, C, D, E} image dataset.\n"
      ],
      "metadata": {
        "id": "nQC13SXQHu63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 examples of each character"
      ],
      "metadata": {
        "id": "syWMAycTNhW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please do not use any other data resources from the web such as the emnist dataset. Figuring out the challenges of making your own handwritten character dataset is part of the exercise for this homework!   \n",
        "\n"
      ],
      "metadata": {
        "id": "6RTUAjVYJU3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission instructions: Include the images you generated as part of your submission. Include any code used for the character image preprocessing. In a README file include details on your data generation process.\n"
      ],
      "metadata": {
        "id": "sjweeNk-JYul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Submit only .py/.ipynb and README files.\n",
        "\n",
        "Code source: https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/mnist_transfer_cnn.py"
      ],
      "metadata": {
        "id": "nVs-bBoZJalq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNdOu42SF7Ks",
        "outputId": "a60d6782-6b44-4b6f-ba7d-d62f45a4f496"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "directory_path = '/content/drive/MyDrive/handwriting/'\n",
        "directory_files = os.listdir(directory_path)\n",
        "data = []\n",
        "label = []\n",
        "\n",
        "for x,i in enumerate(directory_files):\n",
        "    # load the image, pre-process it, and store it in the data list\n",
        "    img_array = cv2.imread(os.path.join(directory_path, i), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    i = i[0:1]\n",
        "    i = int(i)-1\n",
        "    label.append(i)\n",
        "\n",
        "    img_pil = Image.fromarray(img_array)\n",
        "    #img_28x28 = np.array(img_pil.resize((28, 28)))\n",
        "\n",
        "    img_array  = img_array.reshape(-1,1).T\n",
        "    data.append(img_28x28)\n",
        "\n"
      ],
      "metadata": {
        "id": "GyAc2U1AFgSA"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data, dtype=np.uint8)"
      ],
      "metadata": {
        "id": "JjuKz1K0CEmo"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = np.array(label, dtype=np.uint8)\n",
        "label"
      ],
      "metadata": {
        "id": "A7zV5EqVx5YN",
        "outputId": "ef66bc51-6426-4652-e73b-7d10f681ad39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "eWsLUBjxTmG7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,  Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "now = datetime.datetime.now\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "img_rows, img_cols = 221, 229\n",
        "filters = 32\n",
        "pool_size = 2\n",
        "kernel_size = 3\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "metadata": {
        "id": "C1wEBkVk4bAS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H2u08AKdHpso"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,  Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "now = datetime.datetime.now\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "img_rows, img_cols = 28, 28\n",
        "filters = 32\n",
        "pool_size = 2\n",
        "kernel_size = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train, test, num_classes):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "    t = now()\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "ha2657boIIlZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6137PlepImYT",
        "outputId": "c9b0449d-a85d-46bd-bda6-d8c3d7633657"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_gte5.shape"
      ],
      "metadata": {
        "id": "NAwUexvFE4VD",
        "outputId": "0622f248-dbbc-4e20-93f0-4485f5bdc41d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4861, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import datetime\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# number of convolutional filters to use\n",
        "filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = 2\n",
        "# convolution kernel size\n",
        "kernel_size = 3\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "\n",
        "def train_model(model, train, test, num_classes):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    t = now()\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "wSXvLMoOcGlH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create two datasets one with digits below 5 and one with 5 and above\n",
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5"
      ],
      "metadata": {
        "id": "BlS0Mzn2cKxq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define two groups of layers: feature (convolutions) and classification (dense)\n",
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]\n",
        "\n",
        "# create complete model\n",
        "model = Sequential(feature_layers + classification_layers)\n",
        "\n",
        "# train model for 5-digit classification [0..4]\n",
        "train_model(model,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)\n",
        "\n",
        "# freeze feature layers and rebuild model\n",
        "for l in feature_layers:\n",
        "    l.trainable = False\n",
        "\n",
        "# transfer: train dense layers for new classification task [5..9]\n",
        "train_model(model,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp2m1VpyWsqx",
        "outputId": "e61e8349-e874-4209-b4c9-a7ba57024974"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 52s 210ms/step - loss: 1.5989 - accuracy: 0.2408 - val_loss: 1.5615 - val_accuracy: 0.3032\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 49s 203ms/step - loss: 1.5461 - accuracy: 0.3490 - val_loss: 1.5037 - val_accuracy: 0.5882\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 51s 212ms/step - loss: 1.4904 - accuracy: 0.4724 - val_loss: 1.4395 - val_accuracy: 0.7540\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 49s 202ms/step - loss: 1.4288 - accuracy: 0.5735 - val_loss: 1.3668 - val_accuracy: 0.8278\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 50s 209ms/step - loss: 1.3599 - accuracy: 0.6500 - val_loss: 1.2830 - val_accuracy: 0.8638\n",
            "Training time: 0:04:23.840894\n",
            "Test score: 1.2830266952514648\n",
            "Test accuracy: 0.8637867569923401\n",
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 19s 79ms/step - loss: 1.6056 - accuracy: 0.2670 - val_loss: 1.5642 - val_accuracy: 0.3470\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 18s 78ms/step - loss: 1.5568 - accuracy: 0.3050 - val_loss: 1.5123 - val_accuracy: 0.3983\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 18s 78ms/step - loss: 1.5085 - accuracy: 0.3557 - val_loss: 1.4617 - val_accuracy: 0.4598\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 21s 89ms/step - loss: 1.4635 - accuracy: 0.4186 - val_loss: 1.4123 - val_accuracy: 0.5598\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 17s 73ms/step - loss: 1.4179 - accuracy: 0.4800 - val_loss: 1.3644 - val_accuracy: 0.6355\n",
            "Training time: 0:01:32.388953\n",
            "Test score: 1.364380121231079\n",
            "Test accuracy: 0.6354659795761108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_drawn, x_test_drawn, y_train_drawn, y_test_drawn = train_test_split(data, label, test_size=0.3,  random_state=0, stratify=label)\n"
      ],
      "metadata": {
        "id": "0v88IICl_dzJ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_train_drawn = keras.utils.to_categorical(y_train_drawn[1], num_classes)\n",
        "#y_test_drawn = keras.utils.to_categorical(y_test_drawn[1], num_classes)"
      ],
      "metadata": {
        "id": "IEMhSMTA_uDX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_drawn"
      ],
      "metadata": {
        "id": "NSq3jqnxCNgU",
        "outputId": "93dfc48b-baa4-40c4-aa97-b0704a546593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 4, 4, 4, 3, 4, 5, 3, 5, 1, 2, 4, 5, 1, 3, 5, 2, 3, 1, 2, 2,\n",
              "       5, 3, 3, 4, 2, 1, 1, 4, 1, 5, 1, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create complete model\n",
        "model = Sequential(feature_layers + classification_layers)\n",
        "\n",
        "# train model for a-e]\n",
        "train_model(model,\n",
        "            (x_train, y_train),\n",
        "            (x_test, y_test), 10)\n",
        "\n",
        "# freeze feature layers and rebuild model\n",
        "for l in feature_layers:\n",
        "    l.trainable = False\n",
        "\n",
        "# transfer: train dense layers for new classification task [5..9]\n",
        "train_model(model,\n",
        "            (x_train_drawn, y_train_drawn),\n",
        "            (x_test_drawn, y_test_drawn), num_classes)\n"
      ],
      "metadata": {
        "id": "9b5JbkBnF1ao",
        "outputId": "2a979d6a-6b5a-4076-f514-22f59fb9b4c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 19s 78ms/step - loss: 1.0312 - accuracy: 0.8095 - val_loss: 0.9492 - val_accuracy: 0.9058\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 22s 90ms/step - loss: 0.9864 - accuracy: 0.8204 - val_loss: 0.9050 - val_accuracy: 0.9097\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 18s 77ms/step - loss: 0.9484 - accuracy: 0.8314 - val_loss: 0.8631 - val_accuracy: 0.9142\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 20s 83ms/step - loss: 0.9076 - accuracy: 0.8389 - val_loss: 0.8232 - val_accuracy: 0.9173\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 18s 73ms/step - loss: 0.8717 - accuracy: 0.8465 - val_loss: 0.7865 - val_accuracy: 0.9181\n",
            "Training time: 0:02:22.745512\n",
            "Test score: 0.7864692807197571\n",
            "Test accuracy: 0.9180774688720703\n",
            "x_train shape: (34, 28, 28, 1)\n",
            "34 train samples\n",
            "15 test samples\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 2.1957 - accuracy: 0.2647 - val_loss: 2.0979 - val_accuracy: 0.2000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.3494 - accuracy: 0.1176 - val_loss: 2.0960 - val_accuracy: 0.2000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.0772 - accuracy: 0.2059 - val_loss: 2.0941 - val_accuracy: 0.2000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.1115 - accuracy: 0.2059 - val_loss: 2.0925 - val_accuracy: 0.2000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.0825 - accuracy: 0.2647 - val_loss: 2.0907 - val_accuracy: 0.2000\n",
            "Training time: 0:00:01.344892\n",
            "Test score: 2.0907187461853027\n",
            "Test accuracy: 0.20000000298023224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# transfer step: train dense layers for new classification task [a-e]\n",
        "train_model(model,\n",
        "            (x_train_drawn, y_train_drawn),\n",
        "            (x_test_drawn, y_test_drawn), num_classes)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "DE2Zn7L9MAha",
        "outputId": "8b27c327-e579-4837-d99a-d3e9ab90c031"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (34, 28, 28, 1)\n",
            "34 train samples\n",
            "15 test samples\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-ca9a6d322fb3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transfer step: train dense layers for new classification task [a-e]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_model(model,\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mx_train_drawn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_drawn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             (x_test_drawn, y_test_drawn), num_classes)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-600c32ffffbf>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train, test, num_classes)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# convert class vectors to binary class matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 1 with size 5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=data"
      ],
      "metadata": {
        "id": "qX7oPfWvEMgb"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = data[0].shape\n",
        "# number of convolutional filters to use\n",
        "filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = 2\n",
        "# convolution kernel size\n",
        "kernel_size = 3\n",
        "\n",
        "input_shape = (img_rows, img_cols, 1)\n"
      ],
      "metadata": {
        "id": "q0wX8lZ0D50X"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train[0].shape[0],) + input_shape"
      ],
      "metadata": {
        "id": "3E46L5eTFIjf",
        "outputId": "de59cd47-bfbc-4ebe-9141-9a341b4b33ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train_drawn[1], num_classes)\n",
        "y_test = keras.utils.to_categorical(test[1], num_classes)"
      ],
      "metadata": {
        "id": "6Q61ww6gDj0I",
        "outputId": "1c9c4f7a-7d90-4268-c465-5f9d3db729cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-88c96c5b3a8e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (28,28,28,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "t = now()\n",
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "print('Training time: %s' % (now() - t))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "Txx-oTxvDZhl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
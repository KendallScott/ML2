{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+Vck+3oQjI5OFpybKjk14",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/ML2/blob/main/Homework_4_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homework 4: Transfer Learning\n",
        "Below you see a tutorial from Keras on using transfer learning. They train their models on half  the MNIST dataset digits (i.e. digits 0-4) and “transfer” the model to the second half (i.e, digits 5-9).\n",
        "\n"
      ],
      "metadata": {
        "id": "KoIksUP1Hrrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your homework is to train on all digits and make your own handwritten data set of the 5 characters {A, B, C, D, E}  and “transfer” your MNIST trained model over to the dataset you created. In other words, train on the full MNIST datasets (i.e. digits 0-9) and transfer on the {A, B, C, D, E} image dataset.\n"
      ],
      "metadata": {
        "id": "nQC13SXQHu63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 examples of each character"
      ],
      "metadata": {
        "id": "syWMAycTNhW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please do not use any other data resources from the web such as the emnist dataset. Figuring out the challenges of making your own handwritten character dataset is part of the exercise for this homework!   \n",
        "\n"
      ],
      "metadata": {
        "id": "6RTUAjVYJU3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission instructions: Include the images you generated as part of your submission. Include any code used for the character image preprocessing. In a README file include details on your data generation process.\n"
      ],
      "metadata": {
        "id": "sjweeNk-JYul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Submit only .py/.ipynb and README files.\n",
        "\n",
        "Code source: https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/mnist_transfer_cnn.py"
      ],
      "metadata": {
        "id": "nVs-bBoZJalq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNdOu42SF7Ks",
        "outputId": "baa44551-a236-4c74-d09f-2c1b23bab3c8"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "eWsLUBjxTmG7"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,  Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "now = datetime.datetime.now\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "img_rows, img_cols = 221, 229\n",
        "filters = 32\n",
        "pool_size = 2\n",
        "kernel_size = 3\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "metadata": {
        "id": "C1wEBkVk4bAS"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "H2u08AKdHpso"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,  Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "now = datetime.datetime.now\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "img_rows, img_cols = 28, 28\n",
        "filters = 32\n",
        "pool_size = 2\n",
        "kernel_size = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train, test, num_classes, epochs):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "    t = now()\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "ha2657boIIlZ"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5\n"
      ],
      "metadata": {
        "id": "6137PlepImYT"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_gte5.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAwUexvFE4VD",
        "outputId": "b9aee43d-3821-4c05-e6e4-60309e191c0e"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4861, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import datetime\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# number of convolutional filters to use\n",
        "filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = 2\n",
        "# convolution kernel size\n",
        "kernel_size = 3\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "wSXvLMoOcGlH"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create two datasets one with digits below 5 and one with 5 and above\n",
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5"
      ],
      "metadata": {
        "id": "BlS0Mzn2cKxq"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define two groups of layers: feature (convolutions) and classification (dense)\n",
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]\n",
        "\n",
        "# create complete model\n",
        "model = Sequential(feature_layers + classification_layers)\n"
      ],
      "metadata": {
        "id": "Lp2m1VpyWsqx"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train model for 5-digit classification [0..4]\n",
        "train_model(model,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes, 5)\n",
        "\n",
        "# freeze feature layers and rebuild model\n",
        "for l in feature_layers:\n",
        "    l.trainable = False\n",
        "\n",
        "# train model for 5-digit classification [0..4]\n",
        "train_model(model,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes, 5)"
      ],
      "metadata": {
        "id": "5AZsmWzqiOGb",
        "outputId": "3d0193d4-3681-4ada-ded9-77daec5bd829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 54s 220ms/step - loss: 1.6060 - accuracy: 0.2025 - val_loss: 1.5792 - val_accuracy: 0.3071\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 51s 213ms/step - loss: 1.5682 - accuracy: 0.3257 - val_loss: 1.5370 - val_accuracy: 0.6503\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 50s 207ms/step - loss: 1.5290 - accuracy: 0.4458 - val_loss: 1.4913 - val_accuracy: 0.7970\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 49s 206ms/step - loss: 1.4850 - accuracy: 0.5448 - val_loss: 1.4401 - val_accuracy: 0.8544\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 50s 208ms/step - loss: 1.4337 - accuracy: 0.6211 - val_loss: 1.3796 - val_accuracy: 0.8766\n",
            "Training time: 0:04:23.003143\n",
            "Test score: 1.3796383142471313\n",
            "Test accuracy: 0.8766297101974487\n",
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 19s 79ms/step - loss: 1.5839 - accuracy: 0.2703 - val_loss: 1.5561 - val_accuracy: 0.3625\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 18s 77ms/step - loss: 1.5521 - accuracy: 0.3250 - val_loss: 1.5191 - val_accuracy: 0.4754\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 18s 77ms/step - loss: 1.5197 - accuracy: 0.3876 - val_loss: 1.4824 - val_accuracy: 0.5742\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 18s 78ms/step - loss: 1.4863 - accuracy: 0.4559 - val_loss: 1.4466 - val_accuracy: 0.6462\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 18s 77ms/step - loss: 1.4540 - accuracy: 0.5043 - val_loss: 1.4116 - val_accuracy: 0.6898\n",
            "Training time: 0:02:23.044105\n",
            "Test score: 1.411617398262024\n",
            "Test accuracy: 0.6897757649421692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "directory_path = '/content/drive/MyDrive/handwriting/'\n",
        "directory_files = os.listdir(directory_path)\n",
        "data = []\n",
        "label = []\n",
        "\n",
        "for x,i in enumerate(directory_files):\n",
        "    # load the image, pre-process it, and store it in the data list\n",
        "    img_array = cv2.imread(os.path.join(directory_path, i), cv2.IMREAD_GRAYSCALE)\n",
        "    img_array = cv2.resize(img_array, (28, 28))\n",
        "\n",
        "\n",
        "    i = i[0:1]\n",
        "    i = int(i)-1\n",
        "    label.append(i)\n",
        "\n",
        "    img_pil = Image.fromarray(img_array)\n",
        "    img_pil = np.array(img_pil)\n",
        "\n",
        "    img_28x28  = img_pil.reshape(-1,1).T\n",
        "\n",
        "    img_28x28 = np.array(img_28x28.reshape((28, 28)))\n",
        "\n",
        "    data.append(img_28x28)\n",
        "\n"
      ],
      "metadata": {
        "id": "GyAc2U1AFgSA"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].shape"
      ],
      "metadata": {
        "id": "ziNlLHKntLD0",
        "outputId": "a5af59e4-8350-4f5b-f201-da76eed39a14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = np.array(data, dtype=np.uint8)\n",
        "label = np.array(label, dtype=np.uint8)"
      ],
      "metadata": {
        "id": "n2l8F6YgrrSP"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_drawn, x_test_drawn, y_train_drawn, y_test_drawn = train_test_split(data, label, test_size=0.3,  random_state=0, stratify=label)\n"
      ],
      "metadata": {
        "id": "0v88IICl_dzJ"
      },
      "execution_count": 363,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze feature layers and rebuild model\n",
        "for l in feature_layers:\n",
        "    l.trainable = False\n",
        "\n",
        "# transfer: train dense layers for new classification task [5..9]\n",
        "train_model(model,\n",
        "            (x_train_drawn, y_train_drawn),\n",
        "            (x_test_drawn, y_test_drawn), num_classes, 50)"
      ],
      "metadata": {
        "id": "9JLyIQZZhVzU",
        "outputId": "65ad847a-908b-4a09-aebc-cd268bad1ae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (34, 28, 28, 1)\n",
            "34 train samples\n",
            "15 test samples\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6273 - accuracy: 0.2647"
          ]
        }
      ]
    }
  ]
}
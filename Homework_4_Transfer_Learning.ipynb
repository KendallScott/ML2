{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhI1rN1/qQQDQZA8+kc5pE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/ML2/blob/main/Homework_4_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homework 4: Transfer Learning\n",
        "Below you see a tutorial from Keras on using transfer learning. They train their models on half  the MNIST dataset digits (i.e. digits 0-4) and “transfer” the model to the second half (i.e, digits 5-9).\n",
        "\n"
      ],
      "metadata": {
        "id": "KoIksUP1Hrrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your homework is to train on all digits and make your own handwritten data set of the 5 characters {A, B, C, D, E}  and “transfer” your MNIST trained model over to the dataset you created. In other words, train on the full MNIST datasets (i.e. digits 0-9) and transfer on the {A, B, C, D, E} image dataset.\n"
      ],
      "metadata": {
        "id": "nQC13SXQHu63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 examples of each character"
      ],
      "metadata": {
        "id": "syWMAycTNhW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please do not use any other data resources from the web such as the emnist dataset. Figuring out the challenges of making your own handwritten character dataset is part of the exercise for this homework!   \n",
        "\n"
      ],
      "metadata": {
        "id": "6RTUAjVYJU3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission instructions: Include the images you generated as part of your submission. Include any code used for the character image preprocessing. In a README file include details on your data generation process.\n"
      ],
      "metadata": {
        "id": "sjweeNk-JYul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Submit only .py/.ipynb and README files.\n",
        "\n",
        "Code source: https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/mnist_transfer_cnn.py"
      ],
      "metadata": {
        "id": "nVs-bBoZJalq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNdOu42SF7Ks",
        "outputId": "cbc45e8b-9258-47b2-a934-9c80568492a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imread('/content/drive/MyDrive/handwriting/A/a-10.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1318Sz1Hl5G",
        "outputId": "5f664ca4-14cf-4962-81e8-a0ca254b62aa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_array = np.array(image, dtype=\"float\") / 255.0"
      ],
      "metadata": {
        "id": "Lr1hxiYiKP-d"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_array[image_array!=1]"
      ],
      "metadata": {
        "id": "Lxu8CUinKWMm",
        "outputId": "d83ac1fb-a421-4e69-9cee-5540952bb4cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99607843, 0.99607843, 0.99607843, ..., 0.99215686, 0.99215686,\n",
              "       0.99215686])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "directory_path = '/content/drive/MyDrive/handwriting/'\n",
        "directory_files = os.listdir(directory_path)\n",
        "data = []\n",
        "label = []\n",
        "z=0\n",
        "for x,i in enumerate(directory_files):\n",
        "    print(directory_files[z])\n",
        "    # load the image, pre-process it, and store it in the data list\n",
        "    image = cv2.imread(os.path.join(directory_path, i))\n",
        "    impage=np.array(image)\n",
        "    data.append(image)\n",
        "    label.append(i)\n",
        "    # extract the class label from the image path and update the\n",
        "    # labels list\n",
        "\n",
        "\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GyAc2U1AFgSA",
        "outputId": "adcd4406-523b-4096-b6d9-9fc066a25547"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-1bdce4b36353>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (72,) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "id": "6OT2GcMZn0uw",
        "outputId": "192c7564-f890-443d-8fc0-342e322ab467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a-1.jpg',\n",
              " 'a-2.jpg',\n",
              " 'a-3.jpg',\n",
              " 'a-4.jpg',\n",
              " 'a-5.jpg',\n",
              " 'a-6.jpg',\n",
              " 'a-7.jpg',\n",
              " 'a-8.jpg',\n",
              " 'a-9.jpg',\n",
              " 'a-10.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sun-MOVGoaP",
        "outputId": "6ad12b0e-f407-4e8d-97bb-d2fe4e9d8c5f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H2u08AKdHpso"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,  Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "now = datetime.datetime.now\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "img_rows, img_cols = 28, 28\n",
        "filters = 32\n",
        "pool_size = 2\n",
        "kernel_size = 3\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train, test, num_classes):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "    t = now()\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "ha2657boIIlZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6137PlepImYT",
        "outputId": "58d497ba-b8af-433e-f014-4c4f14efe043"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]\n",
        "\n",
        "# create complete model\n",
        "model = Sequential(feature_layers + classification_layers)\n",
        "\n",
        "# train model for 5-digit classification [0..4]\n",
        "train_model(model,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)\n",
        "\n",
        "# freeze feature layers and rebuild model\n",
        "for l in feature_layers:\n",
        "    l.trainable = False\n",
        "\n",
        "# transfer step: train dense layers for new classification task [5..9]\n",
        "train_model(model,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w3l1Z22IEQ1",
        "outputId": "1b6709b4-61f3-4b53-e497-e02be1b6d6b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 44s 182ms/step - loss: 1.6059 - accuracy: 0.2552 - val_loss: 1.5757 - val_accuracy: 0.4407\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 43s 181ms/step - loss: 1.5695 - accuracy: 0.3371 - val_loss: 1.5355 - val_accuracy: 0.5847\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 42s 176ms/step - loss: 1.5312 - accuracy: 0.4261 - val_loss: 1.4944 - val_accuracy: 0.6567\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 43s 181ms/step - loss: 1.4916 - accuracy: 0.4998 - val_loss: 1.4480 - val_accuracy: 0.6962\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 44s 182ms/step - loss: 1.4466 - accuracy: 0.5627 - val_loss: 1.3946 - val_accuracy: 0.7295\n",
            "Training time: 0:03:37.532840\n",
            "Test score: 1.3945945501327515\n",
            "Test accuracy: 0.7295193672180176\n",
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 15s 63ms/step - loss: 1.6168 - accuracy: 0.2424 - val_loss: 1.5890 - val_accuracy: 0.3824\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 16s 68ms/step - loss: 1.5809 - accuracy: 0.2966 - val_loss: 1.5523 - val_accuracy: 0.4834\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 14s 63ms/step - loss: 1.5487 - accuracy: 0.3523 - val_loss: 1.5165 - val_accuracy: 0.5550\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 16s 68ms/step - loss: 1.5159 - accuracy: 0.4106 - val_loss: 1.4815 - val_accuracy: 0.6192\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 16s 68ms/step - loss: 1.4859 - accuracy: 0.4613 - val_loss: 1.4472 - val_accuracy: 0.6869\n",
            "Training time: 0:01:22.685536\n",
            "Test score: 1.447205662727356\n",
            "Test accuracy: 0.6868957281112671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DE2Zn7L9MAha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
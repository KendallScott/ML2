{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtV2vGWuA0g7UYlx3160if",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/ML2/blob/main/Scott_Kendall_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 2"
      ],
      "metadata": {
        "id": "MhTzln4ovoYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is called DeathToGridSearch because with this example you will never have to think about how to manage a large number of classifiers etc simultaneously.  You will now be able to run and collect results in a very straightforward manner.  #LongLongLiveGridSearch!"
      ],
      "metadata": {
        "id": "hCq2lGWUvmiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWlL64LzvfAH"
      },
      "outputs": [],
      "source": [
        "# Homework 2\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score # other metrics too pls!\n",
        "from sklearn.ensemble import RandomForestClassifier # more!\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# adapt this code below to run your analysis\n",
        "# 1. Write a function to take a list or dictionary of clfs and hypers(i.e. use logistic regression), each with 3 different sets of hyper parameters for each\n",
        "# 2. Expand to include larger number of classifiers and hyperparameter settings\n",
        "# 3. Find some simple data\n",
        "# 4. generate matplotlib plots that will assist in identifying the optimal clf and parampters settings\n",
        "# 5. Please set up your code to be run and save the results to the directory that its executed from\n",
        "# 6. Investigate grid search function\n",
        "\n",
        "M = np.array([[1,2],[3,4],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5]])\n",
        "L = np.ones(M.shape[0])\n",
        "n_folds = 5\n",
        "\n",
        "data = (M, L, n_folds)\n",
        "\n",
        "def run (a_clf, data, clf_hyper={}):\n",
        "  M, L, n_folds = data # unpack data container\n",
        "  kf = KFold(n_splits=n_folds) # Establish the cross validation\n",
        "  ret = {} # classic explication of results\n",
        "\n",
        "  for ids, (train_index, test_index) in enumerate(kf.split(M, L)):\n",
        "    clf = a_clf(**clf_hyper) # unpack parameters into clf if they exist\n",
        "    clf.fit(M[train_index], L[train_index])\n",
        "    pred = clf.predict(M[test_index])\n",
        "    ret[ids]= {'clf': clf,\n",
        "               'train_index': train_index,\n",
        "               'test_index': test_index,\n",
        "               'accuracy': accuracy_score(L[test_index], pred)}\n",
        "  return ret\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = run (RandomForestClassifier, data, clf_hyper={})"
      ],
      "metadata": {
        "id": "KeZiCnCGvvf9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}